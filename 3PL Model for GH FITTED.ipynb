{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9eb3c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#=import Pkg; \n",
    "Pkg.add([\"IJulia\", \"CategoricalArrays\", \"LaTeXStrings\",\n",
    "        \"CDMrdata\",  \"RDatasets\",\n",
    "        \"CSV\", \"DataFrames\",    \n",
    "        \"StatsBase\", \"StatsFuns\",  \"Distributions\", \n",
    "        \"Gadfly\", \"Plots\", \"StatsPlots\",\n",
    "        \"Optim\", \"Turing\", \"MCMCChains\", \"DynamicPPL\", \"Zygote\"\n",
    "         ])\n",
    "Pkg.update()\n",
    "=#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7869319c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distributions\n",
    "using DataFrames\n",
    "using Gadfly\n",
    "using Turing\n",
    "using StatsFuns\n",
    "using Plots\n",
    "using StatsPlots\n",
    "using LinearAlgebra\n",
    "using CategoricalArrays\n",
    "using MCMCChains\n",
    "using CSV\n",
    "using CDMrdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c2741d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"COLUMNS\"] = 1000\n",
    "ENV[\"LINES\"] = 10\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e83051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding standard font sizes for all future graphs will make them much easier to read\n",
    "\n",
    "latex_fonts = Theme(major_label_font=\"CMU Serif\", major_label_font_size=22pt,\n",
    "                   minor_label_font=\"CMU Serif\", minor_label_font_size=16pt,\n",
    "                   key_title_font=\"CMU Serif\", key_title_font_size=18pt,\n",
    "                   key_label_font=\"CMU Serif\", key_label_font_size=16pt)\n",
    "Gadfly.push_theme(latex_fonts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ebcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The number of samples is enough to create convergence later on, bigger is usually better but 600 is great\n",
    "samples = 600\n",
    "num_chains = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb07ec4a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=\n",
    "This is the sample of students and the exam scores. There are 536 students represented through rows\n",
    "and 15 questions as columns. A value of \"1\" indicates a question answered correctly and a value of \"0\"\n",
    "an incorrect answer.\n",
    "=#\n",
    "X = DataFrame(CSV.File(\"final_project_Miguel.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294cdd27",
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J = size(X)\n",
    "# Dimension here is due to the IRT model which uses \"I\" as the student dimension and \"J\" as the item/question dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3f0064",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_stacked = DataFrames.stack(X, All())\n",
    "# This will convert the data to a long version so we can calculate the percentage attempts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27d4d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_grp = groupby(X_stacked, :variable)\n",
    "# this will group each repetition of student's answers as one student\n",
    "X_total_items = combine(X_grp, :value => (col -> (sum(col) / 536.0) * 100) => :percentage_attempts)\n",
    "# Now we get the average by performing avg calculations on the column that was grouped, this gets our avg as a float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083cafa2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Gadfly.plot(X_total_items, x = :variable, y = :percentage_attempts, Geom.point,\n",
    "Guide.xlabel(\"Item Number\"), Guide.ylabel(\"Percentage Correct\"), Guide.title(\"Item Performance\")\n",
    ")\n",
    "\n",
    "#Using the gadfly package, I can now place each avg as the individual item performance.\n",
    "#Each point represents the individual item's percentage correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c3dd39",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(X_total_items, x = :percentage_attempts, Geom.density,\n",
    "Guide.xlabel(\"Percentage Correct\"), Guide.ylabel(\"Density\"), Guide.title(\"Student Population Performance\")\n",
    ")\n",
    "#Here's a slightly different way to visualize the above graph, use a density graph to see a continous line "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0d28114",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_likelihood(θ, d, aⱼ, c) # based on the 3-parameter IRT eqn, we'll use theta as \"ability\", d as \"difficulty\", etc\n",
    "    \n",
    "\n",
    "    Pₓ = c .+ (1 .- c).* logistic.(θ * aⱼ.-d) # The dots adjacent to the operators lets us distribute the operation to each element of the array\n",
    "  \n",
    "    return Pₓ\n",
    "end\n",
    "\n",
    "@model function irt_3pl_model(Xᵢ, I, J)\n",
    "    \n",
    "    θ ~ filldist(Normal(0,1), I,1) #theta is the i-th dimension since it refers to students. This prior indicates that student ability is average\n",
    "    aⱼ ~ filldist(LogNormal(0,1), 1,J)\n",
    "    d ~ filldist(Normal(1,1), 1,J) #Using 1,1 for the prior indicates that the test questions were \"harder\" than normal\n",
    "    c ~ filldist(Beta(), 1,J)\n",
    "\n",
    "    Pₓ = calc_likelihood(θ, d, aⱼ, c) \n",
    "    if (Xᵢ != nothing)\n",
    "        Xᵢ .~ Bernoulli.(Pₓ)\n",
    "    else\n",
    "        X ~ arraydist(Bernoulli.(Pₓ))\n",
    "    end\n",
    "    return Pₓ\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b61c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_chain = sample(irt_3pl_model(nothing, I, J), Prior(), samples); #we will sample 600 times from the above distributions\n",
    "#This will be the basis prior chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c1ff54",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior = DataFrame(prior_chain) #this will place our chain in a dataframe\n",
    "df_prior = DataFrames.stack(df_prior, Not([\"iteration\",\"chain\",\"lp\"])) #will convert to long format\n",
    "subset!(df_prior, :variable => ByRow(x-> !contains(x, \"θ\") && !contains(x, \"X\")))#reframes the data so that each row is applied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d0a977",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_plot = Gadfly.plot(df_prior, x=:value, y=:lp, Geom.point, color=:variable, Guide.xlabel(\"Data\"), Guide.ylabel(\"Log Likelihood\"))\n",
    "#This command plots the parameters in the prior to see if they converge. If they don't, we shouldn't proceed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2365508c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "posterior_chain_nuts = sample(irt_3pl_model(Matrix(X), I, J), NUTS(), MCMCThreads(), samples, num_chains);\n",
    "#for the posterior, we will sample from the prior distributions using NUTS algorithm!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd9bc5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "predict_chain = predict(irt_3pl_model(nothing, I, J), #plugging in the model to see how the model will perform\n",
    "posterior_chain_nuts[:,:,1], include_all=false); #this will pull out the first chain as an argument \n",
    "df_predict = DataFrame(predict_chain) #Now we can store the chain into a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f29e8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "select!(df_predict, r\"X\") #this excludes the iterations and chain column so we can combine the rest of the columns accurately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888f2ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_predict = combine(df_predict, All() .=> mode) #now we can see the correct answers for each item for each student in a wide format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb85e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape(Matrix(x_predict), (I,J)) #now the array will reshape to the dimensions IxJ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a9944",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_predict = DataFrame(reshape(Matrix(x_predict), (I,J)), string.(\"T\", string.(1:J, pad = 2)))\n",
    "#plugging in the reshape into a dataframe and clarifying each column as a test item/question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bddc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using similar logic in the item performance graph in ln 11, we stack the predicted data and group by variables to perform\n",
    "#avg calculations, then we stack two layers into gadfly, with the first argument being the predicted and the second the actual\n",
    "#item performance seen in ln 11. Notice the discrepancy between the dots, they mean that the prediction is not spot on.\n",
    "\n",
    "X_stacked_pred = DataFrames.stack(x_predict, All())\n",
    "\n",
    "X_grp_pred = groupby(X_stacked_pred, :variable)\n",
    "X_total_items_pred = combine(X_grp_pred, :value => (col -> (sum(col) / 536.0) * 100) => :percentage_attempts)\n",
    "\n",
    "set_default_plot_size(20cm, 12cm) \n",
    "\n",
    "Gadfly.plot(layer(X_total_items_pred, x = :variable, y = :percentage_attempts, Geom.point, color = [\"Predicted Item Performance\"]),\n",
    "    layer(X_total_items, x = :variable, y = :percentage_attempts, Geom.point, color = [\"Observed Item Data\"]),\n",
    "Guide.xlabel(\"Item Parameter\"), Guide.ylabel(\"Percentage Correct\"), Guide.title(\"Observed vs Predicted Item Performance\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a72cd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Similar to the Student population performance graph from earlier, we compared how the predicted and observed data relate\n",
    "#in a continuous line by creating two layers. Notice the gap in the 60th- 75th parameter.\n",
    "\n",
    "Gadfly.plot(layer(X_total_items_pred, x = :percentage_attempts, Geom.density, color = [\"Predicted Item Performance\"]),\n",
    "    layer(X_total_items, x = :percentage_attempts, Geom.density, color = [\"Observed Item Data\"]),\n",
    "Guide.xlabel(\"Item Parameter\"), Guide.ylabel(\"Percentage Correct\"), Guide.title(\"Observed vs Predicted Item Performance\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63553ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posterior_chain_nuts = DataFrame(describe(posterior_chain_nuts)[1])\n",
    "df_parameter = transform(df_posterior_chain_nuts, :parameters => ByRow(x -> string(string.(x)[1])) => :parameter_type)\n",
    "#We want to store the first chain as a dataframe so we can gather the rhat measurement later on for convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81769e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(df_posterior_chain_nuts, allrows=true) #this will come in handy to check which parameters are converging e.g theta, d, c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615d814d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since rhat values close to 0 means that the parameters have converged, we want to see how each one performed by setting the x \n",
    "#to parameters from above and y to rhat itself. hstack rearranges the plots to see them more clearly\n",
    "h = Gadfly.plot(df_parameter, x = :parameter_type, y = :rhat, Geom.point,\n",
    "Guide.xlabel(\"Type of Parameter\"), Guide.ylabel(\"Rhat\"), Guide.title(\"MCMC Convergence\"), Stat.x_jitter(range=0.2),\n",
    ")\n",
    "hstack(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c813ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_posterior_theta_mean = df_posterior_chain_nuts[1:536,1:2] #this will retrieve the correct columns for theta mean\n",
    "for i in 1:536 #this loop will iterate through each row and assign the correct students' ability posterior\n",
    "    df_posterior_theta_mean[i, 1] = Symbol.(i)\n",
    "end\n",
    "df_posterior_theta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18cd2bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prior_theta_mean = DataFrame(describe(prior_chain)[1])[1:536, 1:2] #this will access the correct columns from the prior chain\n",
    "for i in 1:536 #same concept as in cell before\n",
    "    df_prior_theta_mean[i, 1] = Symbol.(i)\n",
    "end\n",
    "df_prior_theta_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329f5b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#By stacking two layers (prior and posterior estimates) we can see generally across all points if the posterior has diverged from\n",
    "#the prior, whhich it should for Bayesian probability\n",
    "ind_prob_plot = Gadfly.plot(\n",
    "    layer(df_prior_theta_mean, x = 1:nrow(df_prior_theta_mean), y =:mean, Geom.point, color = [\"Prior Estimate\"]),\n",
    "    layer(df_posterior_theta_mean, x = 1:nrow(df_posterior_theta_mean), y =:mean, Geom.point, color = [\"Posterior Estimate\"]),\n",
    "    Guide.xlabel(\"Ability Parameter\"), Guide.ylabel(\"Posterior Mean\"), Guide.colorkey(\"variable\"), Guide.Title(\"Student Ability Prior and Posterior Estimates\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbb00c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to analyze free parameters, we used the similar retrieval of the posterior chain and prior chain, only now\n",
    "#we want to correctly retrieve rows 537-581 and iterate through 45 times since there's 15 questions on the test * 3 parameters\n",
    "#we exclude the ability parameter since we want to evaluate the testing parameters and how much they diverged from the prior\n",
    "item_parameters_prior = DataFrame(describe(prior_chain)[1])[537:581, 1:2]\n",
    "item_parameters_prior.item_num = 1:45\n",
    "\n",
    "item_parameters_posterior = df_posterior_chain_nuts[537:581, :]\n",
    "item_parameters_posterior = item_parameters_posterior[:, 1:2]\n",
    "item_parameters_posterior.item_num = 1:45\n",
    "\n",
    "#graphing\n",
    "ind_prob_plot = Gadfly.plot(\n",
    "    layer(item_parameters_prior, x =:item_num, y =:mean, Geom.point, color = [\"Prior Estimate\"]),\n",
    "    layer(item_parameters_posterior, x =:item_num, y =:mean, Geom.point, color = [\"Posterior Estimate\"]),\n",
    "    Guide.xlabel(\"Item Parameters\"), Guide.ylabel(\"Posterior Mean\"), Guide.colorkey(\"variable\"), Guide.Title(\"Item Prior and Posterior Estimates\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(DataFrame(describe(prior_chain)[1])) #to prepare for the ability vs. difficulty curve, we need to first check\n",
    "#if we have the \"summary statistics\" chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036f928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show(DataFrame(describe(prior_chain)[1])[537:581,:],allrows=true) #this will help us find specific examples of students\n",
    "#that performed avg and students who performed well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4fcd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_difficulty = df_posterior_chain_nuts[552:566, :] #this will be used as the dataframe for one layer\n",
    "#of the difficulty vs. ability graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b755c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ability = DataFrame(df_posterior_chain_nuts[515, :]) #student who performed well\n",
    "#we discovered this student from an earlier analysis of student performance, the slideshow will showcase this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0921c8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ability_avg = DataFrame(df_posterior_chain_nuts[504, :])# this is a student who performed poorly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1191e213",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we layered the mean columns of the avg student and the good student as well as the difficulty of each item.\n",
    "#we wanted to use dots on a x-axis to display the distance between the good student and the bad.\n",
    "#the student dot can only answer questions to the left, so this indicates a good measuring of difficulty\n",
    "ind_prob_plot = Gadfly.plot(\n",
    "    layer(df_ability, x =:mean, y =[0], Geom.point, color = [\"Good Student Ability\"]),\n",
    "    layer(df_ability_avg, x =:mean, y =[0], Geom.point, color = [\"Avg Student Ability\"]),\n",
    "    layer(df_difficulty, x =:mean, y =repeat([0], nrow(df_difficulty)), Geom.point, color = [\"Item Difficulty\"]), size = [3mm],\n",
    "    Guide.xlabel(\"Posterior Mean\"), Guide.ylabel(\"y\"), Guide.colorkey(\"Parameter Type\"), Guide.Title(\"Ability vs Difficulty\")\n",
    ")\n",
    "hstack(ind_prob_plot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "100934a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_param = r\"dⱼ|aⱼ|cⱼ\"\n",
    "item = r\"\\[1,1\\]\"\n",
    "df_item_posterior_mean = subset(DataFrame(describe(posterior_chain_nuts)[1]), :parameters => ByRow(x->contains(string(x),item_param)))\n",
    "#here we want to retrieve the mean by accessing the paramater column from chain 1 of posterior and input the parameters of IRT\n",
    "\n",
    "df_ability_results = DataFrame(describe(posterior_chain_nuts)[1])\n",
    "subset!(df_ability_results, :parameters => ByRow(x->contains(string(x), \"θ\")))\n",
    "#We want to retain the same dimension of array but now isolate the theta or \"ability\" results\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87165653",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_item_curve = transform(df_ability_results, :mean => (x -> calc_likelihood(x, df_item_posterior_mean[1,2], df_item_posterior_mean[2,2], df_item_posterior_mean[3,2])) => :likelihood)\n",
    "#the transform function lets us use our calc_likelihood function to use as an argument to see if ability results can be plugged into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77ff2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(df_item_curve, x=:mean, y=:likelihood, Geom.line, Guide.ylabel(\"Correctness Likelihood\"), Guide.xlabel(\"Ability\"), Guide.title(\"Item Characteristic Curve(1st Item)\"))\n",
    "#finally, by using the model's likelihood function, we can see that as ability increases, the probability of endorsing\n",
    "# a correct answer diminishes. This is quite the opposite of what we were aiming to capture with IRT, so as a\n",
    "# \"business\" decision, we decided not to recommend IRT 3-parameter for potential clients who want to analyze student and \n",
    "#item performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d303f5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
